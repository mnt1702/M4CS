{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Inport necessary packages"
      ],
      "metadata": {
        "id": "HDTNiCTFMkMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "JP7PLCNyyv3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5YxLttjnWkAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YYY1wKteWi-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "nJdWaRvkMuzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "2dw8ElsOMvVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 'Your Student ID here'"
      ],
      "metadata": {
        "id": "g72Nbha2pGLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "Ux1pwHpipCeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Folio Leaf Dataset"
      ],
      "metadata": {
        "id": "eCoKxN-gM6Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = 'The directory contains the Folio Leaf Dataset' # Example: '/content/drive/MyDrive/CS115/Folio Leaf Dataset'"
      ],
      "metadata": {
        "id": "zTjpMINjqyko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_folders = os.listdir(root_dir)\n",
        "list_folders"
      ],
      "metadata": {
        "id": "1zOLYl_Iqyko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize(image):\n",
        "    return cv2.resize(image, (232, 412))"
      ],
      "metadata": {
        "id": "Z8I9PN4ts97c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process the raw data"
      ],
      "metadata": {
        "id": "hdib0J6FPqxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset (X, y)\n",
        "X, y = [], []\n",
        "for folder in list_folders:\n",
        "  list_image_paths = os.listdir(root_dir + '/' + folder)\n",
        "  for image_path in list_image_paths:\n",
        "    img_matrix = resize(cv2.imread(root_dir + '/' + folder + '/' + image_path, 0))\n",
        "    X.append([img_matrix])\n",
        "    y.append(folder)"
      ],
      "metadata": {
        "id": "lMHjHCFJloPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Normalize the value of each pixel by dividing them to 255\n"
      ],
      "metadata": {
        "id": "jw5AlCoxqykq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Perform 'label encoding' on y\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = '...'"
      ],
      "metadata": {
        "id": "U5lpaX6tqykq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "6p8WjtU-ATPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the train/test set"
      ],
      "metadata": {
        "id": "nV3VMG9LPwMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Split dataset into training and testing set (7:3, random_seed = Your Student ID)\n"
      ],
      "metadata": {
        "id": "QrscjPstqykr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = np.array(X_train), np.array(X_test)\n",
        "y_train, y_test = np.array(y_train), np.array(y_test)"
      ],
      "metadata": {
        "id": "8LqXswqNqyks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Convert the data type of X_train, X_test, y_train, y_test to 'Tensor'\n"
      ],
      "metadata": {
        "id": "5Zk2gCWfqyks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Create train_dataset, test_dataset\n"
      ],
      "metadata": {
        "id": "jP7Cz18Iqykt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PHd0ggPMqykt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Create train_loader (batch_size = 64), test_loader\n"
      ],
      "metadata": {
        "id": "6VafzaSKO7EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qG76ZpVPCFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement Classifiers"
      ],
      "metadata": {
        "id": "SzV2uJkDPyvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Implement \"Logistic Regression\" model with PyTorch\n"
      ],
      "metadata": {
        "id": "T4X5BfsQbKrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "1hEhCqsBfWKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4dDN9_Pf2DA",
        "outputId": "5b1e8dcf-d05a-43ca-e227-e738c9a3e7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Design the 'train_model' function for training models\n",
        "# Loss Function: Cross Entropy Loss\n",
        "# Optimizer: Adam -> optim.Adam(model.parameters(), lr=...)\n"
      ],
      "metadata": {
        "id": "pZotr39MfQVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Design the 'model_evaluation' function for evaluating the trained models\n"
      ],
      "metadata": {
        "id": "4Ac_OL87wkO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression model\n",
        "# Input dim = 412 * 232\n",
        "# Output dim = 32\n",
        "# Initial Learning Rate: 0.001\n",
        "# Max Epoch = 600\n"
      ],
      "metadata": {
        "id": "sn9y1nbgymZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, len(loss_each_epoch_LR) + 1), loss_each_epoch_LR)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('LogisticRegression')"
      ],
      "metadata": {
        "id": "R1RsvHAsy2UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logistic Regression (Train Accuracy)')\n",
        "model_evaluation(data_loader=train_loader, model=clf_LR)"
      ],
      "metadata": {
        "id": "gEzLMsJRyAX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logistic Regression (Test Accuracy)')\n",
        "model_evaluation(data_loader=test_loader, model=clf_LR)"
      ],
      "metadata": {
        "id": "RXNug6VYUaSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROW_IMG, N_ROWS = 3, 2\n",
        "\n",
        "fig = plt.figure()\n",
        "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
        "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_dataset[index][0].squeeze(), cmap='gray_r')\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        clf_LR.eval()\n",
        "        X = test_dataset[index][0].reshape(test_dataset[index][0].shape[0], -1).to(device)\n",
        "        _, probs = clf_LR(X)\n",
        "    title = f'Predict: {le.inverse_transform([torch.argmax(probs).item()])[0]} ({torch.max(probs * 100):.0f}%)\\n True Label: {le.inverse_transform([test_dataset[index][-1]])[0]}'\n",
        "    \n",
        "    plt.title(title, fontsize=7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gCrrs6EITLf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Build a MLP model with 6 layers (input layer, ouput layer and 4 hidden layers)\n",
        "# The activation of each node in 'input' layer and 'hidden' layers is ReLU\n",
        "# Information about each layer:\n",
        "# + Input layer: (input_dim, 2048)\n",
        "# + Hidden layer 1: (2048, 1024)\n",
        "# + Hidden layer 2: (1024, 1024)\n",
        "# + Hidden layer 3: (1024, 512)\n",
        "# + Hidden layer 4: (512, 512)\n",
        "# + Output layer: (512, output_dim)\n"
      ],
      "metadata": {
        "id": "r_Pm9qpp2Aa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_MLP = MLP(input_dim=412 * 232, output_dim=32).to(device)\n",
        "clf_MLP"
      ],
      "metadata": {
        "id": "AvgokuKmT6LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train MLP model\n",
        "# Input dim = 412 * 233\n",
        "# Output dim = 32\n",
        "# Initial Learning Rate: 0.001\n",
        "# Max Epoch = 600\n"
      ],
      "metadata": {
        "id": "uJCl4O0RReP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, len(loss_each_epoch_MLP) + 1), loss_each_epoch_MLP)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('MLP')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "46kEeCE4j9AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Multi Layer Perceptron (Train Accuracy)')\n",
        "model_evaluation(train_loader, clf_MLP)"
      ],
      "metadata": {
        "id": "IynO3NcfyT0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Multi Layer Perceptron (Test Accuracy)')\n",
        "model_evaluation(test_loader, clf_MLP)"
      ],
      "metadata": {
        "id": "v7izp5kKUb7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROW_IMG, N_ROWS = 3, 2\n",
        "\n",
        "fig = plt.figure()\n",
        "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
        "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_dataset[index][0].squeeze(), cmap='gray_r')\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        clf_MLP.eval()\n",
        "        X = test_dataset[index][0].reshape(test_dataset[index][0].shape[0], -1).to(device)\n",
        "        _, probs = clf_MLP(X)\n",
        "    title = f'Predict: {le.inverse_transform([torch.argmax(probs).item()])[0]} ({torch.max(probs * 100):.0f}%)\\n True Label: {le.inverse_transform([test_dataset[index][-1]])[0]}'\n",
        "    \n",
        "    plt.title(title, fontsize=7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6lEF38rx5VC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}